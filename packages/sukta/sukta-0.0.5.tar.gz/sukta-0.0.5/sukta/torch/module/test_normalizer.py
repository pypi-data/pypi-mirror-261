import numpy as np
import torch

import sukta.torch.tensor_util as stzu
import sukta.tree_util as stu
from sukta.torch.normalizer_util import get_image_range_normalizer

from .normalizer import LinearNormalizer, SingleFieldLinearNormalizer


def test_no_data_hierarchy_normalizer():
    data = torch.zeros((100, 10, 9, 2)).uniform_()
    data[..., 0, 0] = 0

    normalizer = SingleFieldLinearNormalizer()
    normalizer.fit(data, mode="limits", last_n_dims=2)
    datan = normalizer.normalize(data)
    assert datan.shape == data.shape
    assert np.allclose(datan.max(), 1.0)
    assert np.allclose(datan.min(), -1.0)
    dataun = normalizer.unnormalize(datan)
    assert torch.allclose(data, dataun, atol=1e-7)

    input_stats = normalizer.get_input_stats()
    print(stzu.to_numpy(input_stats))
    output_stats = normalizer.get_output_stats()
    print(stzu.to_numpy(output_stats))

    normalizer = SingleFieldLinearNormalizer()
    normalizer.fit(data, mode="limits", last_n_dims=1, fit_offset=False)
    datan = normalizer.normalize(data)
    assert datan.shape == data.shape
    assert np.allclose(datan.max(), 1.0, atol=1e-3)
    assert np.allclose(datan.min(), 0.0, atol=1e-3)
    dataun = normalizer.unnormalize(datan)
    assert torch.allclose(data, dataun, atol=1e-7)

    data = torch.zeros((100, 10, 9, 2)).uniform_()
    normalizer = SingleFieldLinearNormalizer()
    normalizer.fit(data, mode="gaussian", last_n_dims=0)
    datan = normalizer.normalize(data)
    assert datan.shape == data.shape
    assert np.allclose(datan.mean(), 0.0, atol=1e-3)
    assert np.allclose(datan.std(), 1.0, atol=1e-3)
    dataun = normalizer.unnormalize(datan)
    assert torch.allclose(data, dataun, atol=1e-7)

    # dict
    data = torch.zeros((100, 10, 9, 2)).uniform_()
    data[..., 0, 0] = 0

    normalizer = LinearNormalizer()
    normalizer.fit(data, mode="limits", last_n_dims=2)
    datan = normalizer.normalize(data)
    assert datan.shape == data.shape
    assert np.allclose(datan.max(), 1.0)
    assert np.allclose(datan.min(), -1.0)
    dataun = normalizer.unnormalize(datan)
    assert torch.allclose(data, dataun, atol=1e-7)

    input_stats = normalizer.get_input_stats()
    output_stats = normalizer.get_output_stats()

    data = {
        "obs": torch.zeros((1000, 128, 9, 2)).uniform_() * 512,
        "action": torch.zeros((1000, 128, 2)).uniform_() * 512,
    }
    normalizer = LinearNormalizer()
    normalizer.fit(data)
    datan = normalizer.normalize(data)
    dataun = normalizer.unnormalize(datan)
    for key in data:
        assert torch.allclose(data[key], dataun[key], atol=1e-4)

    input_stats = normalizer.get_input_stats()
    output_stats = normalizer.get_output_stats()

    state_dict = normalizer.state_dict()
    n = LinearNormalizer()
    n.load_state_dict(state_dict)
    datan = n.normalize(data)
    dataun = n.unnormalize(datan)
    for key in data:
        assert torch.allclose(data[key], dataun[key], atol=1e-4)


def test_hierarchical_data_normalizer():
    data = {
        "obs": {
            "qpos": torch.zeros((1000, 128, 9, 2)).uniform_() * 512,
            "qvel": torch.zeros((1000, 128, 9, 2)).uniform_() * 512,
        },
        "action": torch.zeros((1000, 128, 2)).uniform_() * 512,
    }
    normalizer = LinearNormalizer()
    normalizer.fit(data)
    datan = normalizer.normalize(data)
    dataun = normalizer.unnormalize(datan)
    for path, value in stu.iter_path(data):
        assert torch.allclose(value, stu.dict_get_path(dataun, path), atol=1e-4)

    input_stats = normalizer.get_input_stats()
    output_stats = normalizer.get_output_stats()

    state_dict = normalizer.state_dict()

    n = LinearNormalizer()
    n.load_state_dict(state_dict)
    datan = n.normalize(data)
    dataun = n.unnormalize(datan)
    for path, value in stu.iter_path(data):
        assert torch.allclose(value, stu.dict_get_path(dataun, path), atol=1e-4)


def test_hierarchical__post_norm_data_normalizer():
    data = {
        "obs": {
            "qpos": torch.zeros((100, 64, 9, 2)).uniform_() * 512,
            "qvel": torch.zeros((100, 64, 9, 2)).uniform_() * 512,
        },
        "action": torch.zeros((100, 64, 2)).uniform_() * 512,
    }
    normalizer = LinearNormalizer()
    normalizer.fit(data)
    normalizer["obs/image"] = get_image_range_normalizer()
    stu.dict_set_path(
        data,
        "obs/image".split("/"),
        torch.rand((100, 64, 84, 84), dtype=torch.float32),
    )
    datan = normalizer.normalize(data)
    dataun = normalizer.unnormalize(datan)
    for path, value in stu.iter_path(data):
        assert torch.allclose(value, stu.dict_get_path(dataun, path), atol=1e-4)

    input_stats = normalizer.get_input_stats()
    output_stats = normalizer.get_output_stats()

    state_dict = normalizer.state_dict()

    n = LinearNormalizer()
    n.load_state_dict(state_dict)
    datan = n.normalize(data)
    dataun = n.unnormalize(datan)
    for path, value in stu.iter_path(data):
        assert torch.allclose(value, stu.dict_get_path(dataun, path), atol=1e-4)
