Metadata-Version: 2.1
Name: mcnets
Version: 2.0.0
Summary: Various machine learning models that use unique Monte Carlo-type parameter training.
Project-URL: Homepage, https://github.com/SciCapt/Monte-Carlo-Neural-Nets
Project-URL: Bug Tracker, https://github.com/SciCapt/Monte-Carlo-Neural-Nets/issues
Author-email: Sean <svs.2k15@gmail.com>
License-File: LICENSE
Classifier: License :: OSI Approved :: MIT License
Classifier: Operating System :: OS Independent
Classifier: Programming Language :: Python :: 3
Requires-Python: >=3.7
Description-Content-Type: text/markdown

# Monte-Carlo-Neural-Nets

## Overview

A package made to see how well a basic architecture of neural nets could be. The nets can be created with custom input and output heights, as well as full customization of the hidden layers' sizes (height and count of layers) and activation functions that are applied at each space between the layers.

The basic operation of these nets is that they can be trained to some data set (or some score in an unsupervised case) by randomly 'tweaking' the different parameter weight values within the net. These weight values are clipped to be restrained to the range [-1, 1].

As of recent versions (>1.4.0) there are now a variety of different models to try and use (SUNN, MCSoupRegressor, MCSoupClassifier and MCSimpleEnsemble). Each one works in different ways, but they all support the typical .fit, .predict, .score, etc. methods. They all still use various Monte Carlo training algorithms tailored to how each one works.

## GitHub and QuickStart
Given on the GitHub page below is a quick start code that shows the syntax for creating a network, a few ways to write in the activation functions to be used, the included train-test split function, fitting the models, getting their predictions, and the plots of the resulting predictions.

More explanations, examples, and technicals can be found on the GitHub page:
https://github.com/SciCapt/Monte-Carlo-Neural-Nets

