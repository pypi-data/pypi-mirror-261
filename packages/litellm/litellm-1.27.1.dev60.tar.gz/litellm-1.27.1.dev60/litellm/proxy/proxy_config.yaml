model_list:
  - model_name: anthropic-claude-v2
    litellm_params:
      model: bedrock/anthropic.claude-v2
      aws_arn_arguments: {
          "landing_role_arn": "arn:aws:iam::123456789012:role/landing-role",
          "landing_role_session_name": "eks_landing_session",
          "aws_web_identity_token_file": "proxy_server.py",
          "bedrock_role_arn": "arn:aws:iam::999999999:role/tiaa-xyz-dev-ue1-carn-eks234-crossaccount",
          "bedrock_role_session_name": "bedrock-crossaccount-session"
      }
  - model_name: mistral
    litellm_params:
      model: sagemaker/jumpstart-dft-hf-llm-mistral-7b-instruct
      aws_arn_arguments: {
          "landing_role_arn": "arn:aws:iam::123456789012:role/landing-role",
          "landing_role_session_name": "eks_landing_session",
          "aws_web_identity_token_file": "proxy_server.py",
          "sagemaker_role_arn": "arn:aws:iam::999999999:role/tiaa-xyz-dev-ue1-carn-eks234-crossaccount",
          "sagemaker_role_session_name": "sagemaker-crossaccount-session"
      }
litellm_settings:
  fallbacks: [{"openai-gpt-3.5": ["azure-gpt-3.5"]}]
  success_callback: ['langfuse']
  # setting callback class
  # callbacks: custom_callbacks.proxy_handler_instance # sets litellm.callbacks = [proxy_handler_instance]

general_settings: 
  alerting: ["slack"]
  alerting_threshold: 10 # sends alerts if requests hang for 2 seconds
  # database_type: "dynamo_db" 
  # database_args: { # ðŸ‘ˆ  all args - https://github.com/BerriAI/litellm/blob/befbcbb7ac8f59835ce47415c128decf37aac328/litellm/proxy/_types.py#L190
  #   "billing_mode": "PAY_PER_REQUEST", 
  #   "region_name": "us-west-2",
  #   "ssl_verify": False
  # }





environment_variables: 
  # otel: True          # OpenTelemetry Logger
  # master_key: sk-1234 # [OPTIONAL] Only use this if you to require all calls to contain this key (Authorization: Bearer sk-1234)
