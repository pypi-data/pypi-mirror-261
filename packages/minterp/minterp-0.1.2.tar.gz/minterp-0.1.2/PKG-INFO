Metadata-Version: 2.1
Name: minterp
Version: 0.1.2
Summary: 
License: MIT
Author: fergus
Author-email: fergusfettes@gmail.com
Requires-Python: >=3.10,<4.0
Classifier: License :: OSI Approved :: MIT License
Classifier: Programming Language :: Python :: 3
Classifier: Programming Language :: Python :: 3.10
Classifier: Programming Language :: Python :: 3.11
Requires-Dist: nnsight (>=0.2.6,<0.3.0)
Requires-Dist: plotly (>=5.19.0,<6.0.0)
Requires-Dist: torchmetrics (>=1.3.1,<2.0.0)
Description-Content-Type: text/markdown

# Summary of Module Development

## Overview

The development of this module focuses on enhancing flexibility and efficiency in handling model states, layer specifications, and dynamic slice evaluations within neural network experiments. The module introduces a robust framework for managing states across multiple forward passes, manipulating model layers and positions with precision, and implementing dynamic configurations tailored to various experimental needs.

## Key Components

- **StateManager**: Centralizes the management of model states, facilitating the saving, loading, and manipulation of states across different stages of model execution. It operates based on configurable rules defined per experiment phase.

- **StateConfig**: Configures the StateManager by specifying which states to save or load during different execution phases. It dynamically adjusts to focus on relevant states at each step, enabling efficient memory use and streamlined state management.

- **Context (RepresentationContext)**: Defines the experimental setup or context for each model execution phase, including aspects like target prompts, layer specifications, and position handling. It supports clone operations with overrides to transition between experimental phases easily.

- **ModelWrapper**: Acts as the execution layer for the model, interpreting Context directives, interacting with the StateManager to apply configurations, and managing model inputs/outputs. It includes logic to resolve dynamic layer and position specifications based on model architecture.

## Features

- **Dynamic Layer and Position Specification**: Facilitates flexible specification of model layers and positions for analysis or manipulation, including support for slices (e.g., "first half of the layers") and dynamic evaluations (e.g., use of "n//3" to specify a third of the layers).

- **Configurable State Management**: Allows for tailored configurations per experimental phase, detailing which model states are crucial for saving, loading, or discarding, thus optimizing resource use.

- **Secure Slice Evaluation**: Implements a safe method to parse and evaluate slice expressions dynamically, considering the total number of layers or positions available in the model, without risking arbitrary code execution.

## Planning and Implementation Considerations

- **Security in Dynamic Evaluations**: Emphasized the importance of safely evaluating dynamic expressions, particularly when dealing with slice notations that involve the model's structural parameters (e.g., the number of layers).

- **Flexibility in Experiment Design**: Prioritized the ability to easily transition between experiment phases through dynamic context adjustments and state configuration updates, ensuring a wide range of experimental designs can be accommodated without extensive code changes.

- **Efficient State and Memory Management**: Addressed efficiency by devising a system that selectively saves or loads states as needed, reducing memory footprint and enhancing execution speed.

## Conclusion

The module represents a comprehensive approach to managing neural network experiment states, layer and position specifications, and dynamic configurations. It is designed to offer flexibility, security, and efficiency, catering to the diverse and evolving needs of neural network research experimentation.

