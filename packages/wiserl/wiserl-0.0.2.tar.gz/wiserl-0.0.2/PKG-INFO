Metadata-Version: 2.1
Name: wiserl
Version: 0.0.2
Summary: A library desgined for Offline Preference-Based RL algorithms. 
Home-page: https://github.com/typoverflow/WiseRL
Author: typoverflow
Author-email: typoverflow@outlook.com
License: MIT
Requires-Python: >=3.7
Description-Content-Type: text/markdown
License-File: LICENSE
Requires-Dist: gym<=0.24.1,>=0.23.1
Requires-Dist: tqdm
Requires-Dist: numpy
Requires-Dist: torch
Requires-Dist: torchvisionpandas
Requires-Dist: UtilsRL

<p align="center">

<img src="assets/banner.png">

</p>

> ðŸš§ This repo is subject to major API changes ðŸš§

WiseRL provides unofficial and banchmarked PyTorch implementations for Offline Preference-Based RL algorithms, including:
- Oracle-IQL & Oracle AWAC
- Supervised Finetuning (SFT)
- BT Model + IQL/AWAC (BT-IQL/AWAC)
- Contrastive Prefereing Learning (CPL)
- Inverse Preference Learning + IQL/AWAC (IPL-IQL/AWAC)

# Installation
+ clone this repo and install the dependencies
  ```bash
  git clone git@github.com:typoverflow/WiseRL
  cd WiseRL && pip install -e .
  ```
+ install environment or dataset dependencies
  + for D4RL experiments:
    ```bash
    git clone https://github.com/Farama-Foundation/d4rl.git
    cd d4rl
    pip install -e .
    ```
  + for metaworld experiments:
    ```bash
    git clone git@github.com:Farama-Foundation/Metaworld
    cd Metaworld && git checkout 04be337a
    pip install -e .
    ```
