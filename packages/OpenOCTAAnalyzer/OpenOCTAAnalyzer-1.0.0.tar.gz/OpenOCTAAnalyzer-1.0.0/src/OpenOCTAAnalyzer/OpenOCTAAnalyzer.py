# OCTAnalyzer.py

"""
Open OCTA Analyzer v 1.0
(C) 2023 - 2024 by Claus von der Burchard

This library allows to automatically quantify and compare OCTA images
Please visit https://github.com/clausvdb/OpenOCTAAnalyzer for further information
"""


__author__ = "Claus von der Burchard"
__copyright__ = "Copyright 2023-2024"
__credits__ = ["Claus von der Burchard"]
__license__ = "CC BY-NC-SA 4.0, https://creativecommons.org/licenses/by-nc-sa/4.0/"
__version__ = "1.0.0"
__maintainer__ = "Claus von der Burchard"
__email__ = "claus.vonderburchard@uksh.de"
__homepage__ = "https://github.com/clausvdb/OpenOCTAAnalyzer"


import matplotlib.pyplot as plt
from skimage import data
import skimage 
from skimage.filters import threshold_otsu, frangi
import cv2
import numpy as np
from .OpenOCTAAnalyzerFilters import OpenOCTAAnalyzerFilters

import PyPDF2
import os
import SimpleITK as sitk

from typing import Union, List

import nibabel as nib
import numpy as np
import os.path as path

import pandas as pd

import pickle


def localizeEdgesAndFovea(image, edgeColor=[0,0,255], foveaColor=[0,255,0]):
    """ Locates the edges and the fovea position in a localizer image that is marked by colored pixels.
    How it works: Create a localizer image where two pixels at the top left and bottom right corner are marked with a distinct color.
    The function will return the coordinates of all pixels within this boundary (i.e. pixels not included) as a template for other images to be cropped.
    
    Parameters
    ----------
    input : str | ndarray
        Either path to file or image object
    edgeColor : array | None. Standard color is blue (RGB 0,0,255).
        Defines the pixel color to look for. The given color may only exist in exactly two pixels in the localizer image.
        If None, no edge detection is performed.
    foveaColor : array | None. Standard color is green (RGB 0,255,0).
        Defines the pixel color to look for. The given color may only exist in exactly one pixel in the localizer image.
        If None, no fovea detection is performed. 
    
    Returns
    -------
    Dictionary {
        edges: [top left (array(2)), bottom right (array(2))],
        foveaPos: array(2) # Fovea Pos in cropped image
        foveaPosOriginal: array(2) # Fovea Pos in orginial image
    }
    """

    retVal = {}


    if edgeColor != None:
        edges = np.where(np.all(image == edgeColor, axis=-1))
        if len(edges[0]) != 2:
            raise Exception(f"Incorrect number of edges found ({len(edges[0])}). Please define exactly two edges.")
        posTopLeft = [np.min(edges[0] + 1), np.min(edges[1]) + 1]
        posBottomRight = [np.max(edges[0]), np.max(edges[1])]
        retVal["edges"] = [posTopLeft, posBottomRight]

    if foveaColor != None:
        foveaPos = np.where(np.all(image == foveaColor, axis=-1))
        if len(foveaPos[0]) != 1:
            raise Exception(f"Incorrect number of fovea positions found ({len(foveaPos[0])}). Please define exactly one fovea position.")
        retVal["foveaPosOriginal"] = [foveaPos[0][0], foveaPos[1][0]]
        if edgeColor != None:
            retVal["foveaPos"] = [foveaPos[0][0]-posTopLeft[0], foveaPos[1][0]-posTopLeft[1]]

    return retVal

def cropByEdges(image, pos):
    """Crop image based on Edges determined by localizeEdgesAndFovea function
    
    Parameters
    ----------
    input : ndarray
        Image to be cropped
    pos: dict
        dict containing "edges" array as defined by localizeEdgesAndFovea function

    Returns
    -------
    ndarray: cropped image
    """
    return image[pos["edges"][0][0]:pos["edges"][1][0], pos["edges"][0][1]:pos["edges"][1][1]]

def image2Nifti(input: Union[str, np.ndarray], output: str="", cropArray: dict = None):
    """Converts an image (preferred type PNG) to Nifti

    `input` can be a file path or an image object.

    Parameters
    ----------
    input : str | ndarray
        Either path to file or image object
    output : str, optional
        Filename to save NII to. Can be autogenerated from input, if input is string format
    cropArray: dict, optional
        information on how to crop the image (only if filename is given)
    """

    if type(input) is str:
        image = skimage.io.imread(input)
        image = image[:,:,1]

        if cropArray != None:
            image = cropByEdges(image, cropArray)
            if "resize" in cropArray:
                image = cv2.resize(image, cropArray['resize'])

        if output == "":
            output = path.splitext(input)[0] + ".nii"
    else:
        image = np.copy(input)

        if output == "":
            output = "output.nii"
    
    image = np.moveaxis(image, -1, 0)
    image = np.flip(image, 1)

    ni_img = nib.Nifti1Image(image, np.eye(4))

    nib.save(ni_img, output)


def double_segmentation(segfile: str, outputfile: str, segtodouble: int, doubledsegmentation: int, segstooverwrite = [0]):
    """ Function to create a penumbra with twice the sice of a given segmentation. Useful to compare vessel density to directly surrounding tissue.
    
    Parameters
    ----------
    segfile: str
        Path to segmentation file
    output: str
        Path to output segmentation file with doubled segmentation. If None, will not be saved.
    segtodouble: int
        Integer of segmentation to be doubled
    doubledsegmentation: int
        Integer of the doubled segmentation
    segstooverwrite: List[int], optional
        Which other segmentations should be overwritten. Standard value [0] (only background is overwritten)

    Returns
    -------
    The doubled segmentation.
    """
    
    import nibabel as nib
    import numpy as np
    from scipy.ndimage import measurements, zoom

    # Load the segmentation file
    seg_img = nib.load(segfile)

    # Get the segmentation data
    seg_data = seg_img.get_fdata()

    # Convert the segmentation to a binary mask
    mask = np.where(seg_data == segtodouble, doubledsegmentation, 0)

    # Compute the gravitational center of the mask
    center = measurements.center_of_mass(mask)

    # Translate the binary mask so that the center is at the origin
    translation = -np.array(center)
    translated_mask = np.roll(mask, translation.astype(int), axis=(0,1,2))

    # Double the size of the translated mask while keeping the center fixed
    zoomed_mask = zoom(translated_mask, zoom=[2,2,1], order=0)

    # Translate the zoomed mask so that the center is restored to its original position
    inv_translation = np.array(center)
    translated_zoomed_mask = np.roll(zoomed_mask, inv_translation.astype(int), axis=(0,1,2))
    # translated_zoomed_mask = translated_zoomed_mask[0:len()]

    # Convert the translated zoomed mask back to the original data type of the segmentation
    zoomed_data = np.round(translated_zoomed_mask).astype(seg_data.dtype)
    a,b,c = np.shape(mask)
    zoomed_data = zoomed_data[0:a, 0:b, 0:c]


    # Get boolean array of all pixels that may be overwritten
    overwrite = np.isin(seg_data, segstooverwrite)

    # Get boolean array of all pixels of zoomed_data with the doubled segmentation
    overwrite2 = (zoomed_data == doubledsegmentation)

    # Combine the array
    overwrite = overwrite & overwrite2
    seg_data[overwrite] = zoomed_data[overwrite]

    # Save the result as a Nifti file
    doubled_img = nib.Nifti1Image(seg_data, seg_img.affine, seg_img.header)
    if outputfile is not None:
        nib.save(doubled_img, outputfile)
    return seg_data


def analyzeSegmentations(imgsrcs, segmentations, filters={"raw": OpenOCTAAnalyzerFilters.standardRaw, "otsu": OpenOCTAAnalyzerFilters.standardOtsu, "frangi": OpenOCTAAnalyzerFilters.standardFrangi, "gradient": OpenOCTAAnalyzerFilters.standardGradient}, output_excel_file: str ="", output_pdf_file: str=""):
    """
    The main function to perform vessel density analysis.

    Parameters
    ----------
    imgsrcs: List[str]
        List of all image files (filename) to be analyzed
    segmentations: List[ndarrays]
        List of all segmentations (already have to be loaded into numpy array) to be analyzed
    filters: dict{filtername: filterfunc, ...}, optional
        List of all filters that will be applied for analysis. Standard filters are raw, otsu, frangi and gradient
    output_excel_file: str, optional
        If defined, the analysis (also in return value) will be saved to this path in xlsx format.

    Returns
    -------
    Analysis in Dictionary format.
    """
    ret = {}

    output_image_rows = [[None] * len(filters)] * len(imgsrcs)
    plots = [None] * len(segmentations)
    axs = [None] * len(segmentations)

    for i, f in enumerate(filters):
        thisfilter = {}
        for j, imgsrc in enumerate(imgsrcs):
            image = loadNifti(imgsrc)

            ret2 = {}
            cur_filter = filters[f](image)
            for k, x in enumerate(segmentations): 
                if not plots[k]:
                    plots[k], axs[k] = plt.subplots(len(imgsrcs), len(filters), figsize=(20, 20))
                    plots[k].suptitle(x, fontsize=16)

                cur_seg = segmentations[x]
                cur_img = cur_seg * cur_filter
                

                save_img = cur_img * 255 if np.max(cur_img) == True else cur_img
                cur_img_rgb = np.stack((save_img,) * 3, axis=-1)

                # Step 2: Set all pixels where cur_seg is 0 to a dark red
                dark_red = np.array([100, 0, 0])  # Dark red color
                cur_img_rgb[np.logical_not(cur_seg)] = dark_red
                
                pixels = cur_seg.sum()
                avg = cur_img.sum() / pixels 
                if np.max(cur_img) > 1:
                    avg /= 255

                axs[k][j,i].imshow(cur_img_rgb)
                axs[k][j,i].set_title(f'{path.basename(imgsrc)}\n{f}\nVAD: {avg:.02f}')
                
                axs[k][j,i].axis('off')
                # Debug: If you want the pixel numbers
                #print(f"{f}_{imgsrc}_{x}: {cur_img.sum()} / {pixels} = {avg}")
                ret2[x] = avg
            imgsrc = path.basename(imgsrc)
            thisfilter[imgsrc] = ret2
        ret[f] = thisfilter

    if output_pdf_file:
        tmp_pdfs = []
        for k, x in enumerate(segmentations): 
            plots[k].tight_layout()
            plots[k].savefig(f"tmp_seg{x}.pdf")
            tmp_pdfs.append(f"tmp_seg{x}.pdf")
            plt.close(plots[k])

        merge_pdfs(output_pdf_file, tmp_pdfs)
        delete_files(tmp_pdfs)

    # Write excel, if excel file is specified
    if output_excel_file:
        import pandas as pd

        writer = pd.ExcelWriter(output_excel_file, engine="xlsxwriter")
        for key in ret:
            df = pd.DataFrame(ret[key])
            df.to_excel(writer, sheet_name=key)
        writer.close()

    return ret

def merge_pdfs(output_path: str, input_paths: List[str]):
    """
    Merge multiple pdfs into one

    Parameters
    ----------
    output_path: str
        The filename of the merged pdf
    input_path: List[str]
        List of all single pdfs to merge
    """
    merger = PyPDF2.PdfMerger()

    for pdf in input_paths:
        merger.append(pdf)

    merger.write(output_path)
    merger.close()

def delete_files(files):
    """ Deletes all files in list """
    for file in files:
        os.remove(file)

def loadNifti(src: str):
    """ Loads nifti in correct orientation """
    sitk_img = sitk.ReadImage(src)
    return np.flip(sitk.GetArrayFromImage(sitk_img), axis=0)

def loadSegmentation(src: str):
    """ Loads Segmentation in correct orientation """
    sitk_img = sitk.ReadImage(src)
    return np.flip(sitk.GetArrayFromImage(sitk_img), axis=1)[0,:,:]
    #return loadNifti(src)[0,:,:]

def createRingSegmentationDiameter(input_segmentation, center: tuple, outer_radius: int, inner_radius: int = 0) -> np.ndarray:
    """ Creates a ring segmentation concentric to [center] with inner and outer radius"""

    from skimage import draw

    new_filter = np.full(np.shape(input_segmentation), False)
    rr, cc = draw.disk(center, radius=outer_radius, shape=input_segmentation.shape)
    new_filter[rr, cc] = True
    if inner_radius > 0:
        rr, cc = draw.disk(center, radius=inner_radius, shape=input_segmentation.shape)
        new_filter[rr, cc] = False

    return new_filter

def createRingSegmentation(input_segmentation: np.ndarray, seg, center: tuple) -> np.ndarray:
    """ Creates a ring segmentation concentric to [center] which incorporates the input_segmentation"""

    from skimage import draw

    # Find the closest point within the shape to x
    indices = np.argwhere(input_segmentation == seg)
    distances_to_x = np.linalg.norm(indices - np.array(center), axis=1)
    closest_point = tuple(indices[np.argmin(distances_to_x)])

    # Find the farthest point within the shape to x
    farthest_point = tuple(indices[np.argmax(distances_to_x)])

    inner_circle_radius = np.floor(np.linalg.norm(np.array(closest_point) - np.array(center))).astype(int)
    outer_circle_radius = np.ceil(np.linalg.norm(np.array(farthest_point) - np.array(center))).astype(int)

    new_filter = np.full(np.shape(input_segmentation), False)
    rr, cc = draw.disk(center, radius=outer_circle_radius, shape=input_segmentation.shape)
    new_filter[rr, cc] = True
    rr, cc = draw.disk(center, radius=inner_circle_radius, shape=input_segmentation.shape)
    new_filter[rr, cc] = False

    return new_filter

def createWedge(input_segmentation: np.ndarray, center: tuple, xy_direction: tuple) -> np.ndarray:
    """ Creates a wedge from the center into direction xy
    Directions: (1,0)  = bottom
                (-1,0) = top
                (0,1)  = right
                (0,-1) = left
    """
    new_filter = np.full(np.shape(input_segmentation), False)

    if xy_direction[1] != 0:
        # going x direction
        to_x = 0 if xy_direction[1] < 0 else np.shape(input_segmentation)[1]

        yPos1 = center[0]
        yPos2 = center[0] + 1
        yMin = 0
        yMax = np.shape(input_segmentation)[0]

        for x in range(center[1], to_x, xy_direction[1]):
            new_filter[yPos1:yPos2, x]= True
            yPos1 -= 1 if yPos1 > yMin else 0
            yPos2 += 1 if yPos2 < yMax else 0
    else: # if xy_direction[0] != 0:
        # going y direction
        to_y = 0 if xy_direction[0] < 0 else np.shape(input_segmentation)[0]

        xPos1 = center[1]
        xPos2 = center[1] + 1
        xMin = 0
        xMax = np.shape(input_segmentation)[1]

        for y in range(center[0], to_y, xy_direction[0]):
            new_filter[y, xPos1:xPos2]= True
            xPos1 -= 1 if xPos1 > xMin else 0
            xPos2 += 1 if xPos2 < xMax else 0

    return new_filter
