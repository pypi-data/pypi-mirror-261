import abc
from _typeshed import Incomplete
from datasurface.md.AvroSchema import AvroSchema as AvSchema
from datasurface.md.Documentation import Documentation as Documentation
from datasurface.md.Governance import CloudVendor as CloudVendor, DataContainer as DataContainer, DataPlatform as DataPlatform, Dataset as Dataset, Ecosystem as Ecosystem, InfrastructureLocation as InfrastructureLocation, ObjectStorage as ObjectStorage, SchemaProjector as SchemaProjector
from datasurface.md.Lint import ValidationTree as ValidationTree
from datasurface.md.Schema import BigInt as BigInt, Boolean as Boolean, DDLColumn as DDLColumn, DDLTable as DDLTable, DataType as DataType, Date as Date, Decimal as Decimal, IEEE16 as IEEE16, IEEE32 as IEEE32, IEEE64 as IEEE64, Integer as Integer, NVarChar as NVarChar, NullableStatus as NullableStatus, PrimaryKeyStatus as PrimaryKeyStatus, Schema as Schema, SmallInt as SmallInt, Timestamp as Timestamp, TinyInt as TinyInt, VarChar as VarChar, Variant as Variant
from typing import Any

class AmazonAWSDataPlatform(DataPlatform):
    def __init__(self, name: str, doc: Documentation) -> None: ...
    def getSupportedVendors(self, eco: Ecosystem) -> set[CloudVendor]: ...
    def __hash__(self) -> int: ...
    def __eq__(self, __value: object) -> bool: ...
    def isContainerSupported(self, eco: Ecosystem, dc: DataContainer) -> bool: ...
    def lint(self, eco: Ecosystem, tree: ValidationTree): ...
    def getInternalDataContainers(self) -> set[DataContainer]: ...

class AmazonAWSS3Bucket(ObjectStorage, metaclass=abc.ABCMeta):
    def __init__(self, name: str, loc: InfrastructureLocation, endPointURI: str | None, bucketName: str, prefix: str | None) -> None: ...
    def __eq__(self, o: object) -> bool: ...
    def __hash__(self) -> int: ...

class AmazonAWSKinesis(DataContainer, metaclass=abc.ABCMeta):
    endPointURI: Incomplete
    def __init__(self, name: str, loc: InfrastructureLocation, endPointURI: str | None) -> None: ...
    def __eq__(self, o: object) -> bool: ...
    def __hash__(self) -> int: ...
    def projectDatasetSchema(self, dataset: Dataset) -> SchemaProjector: ...

class AmazonAWSDynamoDB(DataContainer, metaclass=abc.ABCMeta):
    endPointURI: Incomplete
    def __init__(self, name: str, loc: InfrastructureLocation, endPointURI: str | None) -> None: ...
    def __eq__(self, o: object) -> bool: ...
    def __hash__(self) -> int: ...
    def projectDatasetSchema(self, dataset: Dataset) -> SchemaProjector: ...

class AmazonAWSSQS(DataContainer, metaclass=abc.ABCMeta):
    queueURL: Incomplete
    def __init__(self, name: str, loc: InfrastructureLocation, queueURL: str | None) -> None: ...
    def __eq__(self, o: object) -> bool: ...
    def __hash__(self) -> int: ...
    def projectDatasetSchema(self, dataset: Dataset) -> SchemaProjector: ...

class GlueDDLSchemaMapper(SchemaProjector):
    def __init__(self, dataset: Dataset) -> None: ...
    def __eq__(self, o: object) -> bool: ...
    def convertDDLTable(self, table: DDLTable) -> DDLTable: ...
    def convertAvroTable(self, table: AvSchema) -> AvSchema: ...
    def computeSchema(self) -> Schema | None: ...

class GlueTable:
    srcTable: Incomplete
    type_mapping: Incomplete
    def __init__(self, table: Dataset) -> None: ...
    def convertToAWSType(self, dataType: DataType) -> str: ...
    def generate_glue_schema(self) -> dict[str, Any] | None: ...
