Metadata-Version: 2.1
Name: okahu_handlers
Version: 0.0.5
Summary: package with callback handler code for observability
Project-URL: Homepage, https://github.com/okahu/demo-repository
Project-URL: Issues, https://github.com/okahu/demo-repository/issues
Author-email: "Okahu Inc." <okahu-pypi@okahu.ai>
License-File: LICENSE
Classifier: License :: OSI Approved :: MIT License
Classifier: Operating System :: OS Independent
Classifier: Programming Language :: Python :: 3
Requires-Python: >=3.8
Requires-Dist: langchain>=0.1.0
Requires-Dist: requests
Provides-Extra: dev
Requires-Dist: faiss-cpu==1.7.4; extra == 'dev'
Requires-Dist: instructorembedding==1.0.1; extra == 'dev'
Requires-Dist: langchain-openai==0.0.5; extra == 'dev'
Requires-Dist: numpy==1.26.4; extra == 'dev'
Requires-Dist: pytest==8.0.0; extra == 'dev'
Requires-Dist: sentence-transformers==2.2.2; extra == 'dev'
Requires-Dist: types-requests==2.31.0.20240106; extra == 'dev'
Description-Content-Type: text/markdown

# Okahu callback handler

This package provides okahu callback handler for tracing callbacks in langchain.

## Installing the package
```
> python3 -m pip install pipenv

> pipenv install okahu-handlers
```

## References

[Managing application dependencies](https://packaging.python.org/en/latest/tutorials/managing-dependencies/)

## Usage
```python
from okahu_handlers.langchain.callback import OkahuCallbackHandler
from langchain.chains import LLMChain
from langchain_openai import OpenAI
from langchain.prompts import PromptTemplate

# Set the OKAHU_API_KEY environment variable, if not set already
os.environ["OKAHU_API_KEY"] = "okh_XXXXXXXX_XXXXXXXXXXXXXXXXXXXXXX"

# Create the callback using the constructor
handler = OkahuCallbackHandler(app_name="my_langchain_app")()
llm = OpenAI()
prompt = PromptTemplate.from_template("1 + {number} = ")

# Constructor callback: First, let's explicitly set the OkahuCallbackHandler when initializing our chain
chain = LLMChain(llm=llm, prompt=prompt, callbacks=[handler])
chain.invoke({"number":2})

# Request callbacks: Finally, let's use the request `callbacks` to achieve the same result
chain = LLMChain(llm=llm, prompt=prompt)
chain.invoke({"number":2}, {"callbacks":[handler]})
    
```

