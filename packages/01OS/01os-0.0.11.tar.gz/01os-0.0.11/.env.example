### SETTINGS
# Copy this file and rename it to ".env" to use it.

# If ALL_LOCAL is False, we'll use OpenAI's services
# else we use whisper.cpp and piper local models
ALL_LOCAL=False
WHISPER_MODEL_NAME="ggml-tiny.en.bin"
WHISPER_MODEL_URL="https://huggingface.co/ggerganov/whisper.cpp/resolve/main/"
TEACH_MODE=False

# Uncomment to set your OpenAI API key
# OPENAI_API_KEY=sk-...

# For TTS, we use the en_US-lessac-medium voice model by default
# Please change the voice URL and voice name if you wish to use another voice
PIPER_VOICE_URL="https://huggingface.co/rhasspy/piper-voices/resolve/main/en/en_US/lessac/medium/"
PIPER_VOICE_NAME="en_US-lessac-medium.onnx"

# If SERVER_START, this is where we'll serve the server.
# If CLIENT_START, this is where the client expects the server to be.
# SERVER_URL=ws://localhost:8000/
SERVER_URL=ws://0.0.0.0:8000/
SERVER_START=True
CLIENT_START=True

# The port to start the local server on
SERVER_LOCAL_PORT=8000

# Explicitly set the client type (macos, rpi)
CLIENT_TYPE=auto

# Control where various operations happenâ€” can be `client` or `server`.
CODE_RUNNER=server
TTS_RUNNER=server # If client, audio will be sent over websocket.
STT_RUNNER=client # If server, audio will be sent over websocket.

# Image capture settings
CAMERA_ENABLED=False

# Camera device selection (Typically 0 for built-in, 1 for USB)
CAMERA_DEVICE_INDEX=0

# Camera warmup time
# This is a workaround for some cameras that don't immediately
# return a properly exposed picture when they are first turned on
CAMERA_WARMUP_SECONDS=0.4

# Debug level
# LOG_LEVEL=DEBUG
LOG_LEVEL="INFO"